{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7250e38-d6dd-4d21-9884-b0ae405a1210",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Code Copied from DiffLogicTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98945340-8182-4ee3-8e29-454cabfca572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "from torch import nn\n",
    "from difflogic import LogicLayer, GroupSum\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchviz import make_dot\n",
    "import sys\n",
    "# used to train the DiffLogic models with different configs taken from config.yaml\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "import random\n",
    "import mnist_dataset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm \n",
    "import difflogic\n",
    "from LogicGraph import * \n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "torch.manual_seed(42)             # PyTorch seed fixing\n",
    "torch.cuda.manual_seed(42)        # PyTorch CUDA seed fixing (if using GPU)\n",
    "np.random.seed(42)                # NumPy seed fixing\n",
    "random.seed(42)                   # Python's built-in random seed fixing\n",
    "\n",
    "# If using CUDA:\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# True: If using 20x20 MNIST \n",
    "# False: If using 28x28 MNIST\n",
    "small_mnist = True\n",
    "\n",
    "# True: Binarized Images \n",
    "# False: Grayscale Images \n",
    "binarize_images = True  \n",
    "\n",
    "# True: Mnist Dataset Digits (0-9) have same number of samples (smaller Dataset)\n",
    "# False: Mnist Dataset Digits (0-9) have orignal distribution (digit 1 has more samples, etc)\n",
    "evenly_partitioned = True\n",
    "\n",
    "# Batch size\n",
    "batch_size = 256\n",
    "# function to binarize an image\n",
    "def binarize(image, threshold=0.5):\n",
    "    return (image > threshold).float()  # Threshold the image to convert to binary (0 or 1)\n",
    "\n",
    "# define the transformation logic based on the toggle\n",
    "if binarize_images:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: binarize(x))  # apply binarization if enabled\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()  # just convert to tensor if not binarizing\n",
    "    ])\n",
    "train_dataset = mnist_dataset.MNIST('./data-mnist', train=True, download=True, remove_border=small_mnist, transform=transform)\n",
    "test_dataset = mnist_dataset.MNIST('./data-mnist', train=False, remove_border=small_mnist, transform=transform)\n",
    "\n",
    "# drop_last = True means it will drop the last incomplete Batch\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "\n",
    "# Make Dataset Evenly Partitioned\n",
    "if evenly_partitioned:\n",
    "    # code below is used so that all classes have the same number of samples\n",
    "    train_targets = train_loader.dataset.targets\n",
    "    test_targets = test_loader.dataset.targets\n",
    "\n",
    "    train_digits_total = []\n",
    "    test_digits_total = []\n",
    "\n",
    "    for i in range(10):\n",
    "        curr_tot_train = torch.sum(train_targets == i).item()\n",
    "        curr_tot_test = torch.sum(test_targets == i).item()    \n",
    "        train_digits_total.append(curr_tot_train)\n",
    "        test_digits_total.append(curr_tot_test)\n",
    "\n",
    "    train_digits_total, test_digits_total\n",
    "\n",
    "    # find the minimum number of samples across all classes\n",
    "    min_samples_train = min(train_digits_total)\n",
    "    min_samples_test = min(test_digits_total)\n",
    "\n",
    "    # function to trim dataset to match the minimum samples for each class and shuffle indices\n",
    "    def trim_dataset(dataset, targets, min_samples):\n",
    "        indices = []\n",
    "        for i in range(10):\n",
    "            class_indices = (targets == i).nonzero(as_tuple=True)[0]  # get indices of class i\n",
    "            class_indices = class_indices[:min_samples]  # trim to min_samples\n",
    "            indices.extend(class_indices)\n",
    "\n",
    "        # shuffle indices after collecting them\n",
    "        indices = torch.tensor(indices)\n",
    "        indices = indices[torch.randperm(indices.size(0))]  \n",
    "\n",
    "        return Subset(dataset, indices)\n",
    "\n",
    "    # trim both train and test datasets to ensure all classes have the same number of samples\n",
    "    trimmed_train_dataset = trim_dataset(train_loader.dataset, train_targets, min_samples_train)\n",
    "    trimmed_test_dataset = trim_dataset(test_loader.dataset, test_targets, min_samples_test)\n",
    "\n",
    "    # create DataLoaders for the trimmed datasets\n",
    "    trimmed_train_loader = DataLoader(trimmed_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    trimmed_test_loader = DataLoader(trimmed_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "\n",
    "    # verify the lengths of the trimmed datasets\n",
    "    len(trimmed_train_loader.dataset), len(trimmed_test_loader.dataset)\n",
    "\n",
    "    train_dataset = trimmed_train_dataset\n",
    "    test_dataset = trimmed_test_dataset\n",
    "    train_loader = trimmed_train_loader\n",
    "    test_loader = trimmed_test_loader\n",
    "\n",
    "dataset_size = len(train_dataset)\n",
    "random_index = random.randint(0, dataset_size - 1)\n",
    "\n",
    "if small_mnist:\n",
    "    image = train_loader.dataset[random_index][0].reshape(20, 20)\n",
    "else:\n",
    "    image = train_loader.dataset[random_index][0].reshape(28, 28)\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "class DiffLogic(nn.Module):\n",
    "    def __init__(self, layers_config, output_size, tau=30):\n",
    "        \"\"\"\n",
    "        Initializes the DiffLogic model with the specified layer configurations, output size, and temperature parameter.\n",
    "\n",
    "        Args:\n",
    "            layers_config (dict): Configuration for each logic layer, including dimensions, device, implementation, connections, and grad factor.\n",
    "            output_size (int): The number of output groups.\n",
    "            tau (int): Temperature parameter for the GroupSum operation.\n",
    "        \"\"\"\n",
    "        super(DiffLogic, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        layers = []\n",
    "        for layer_name, config in layers_config.items():\n",
    "            layer = LogicLayer(\n",
    "                in_dim=config['in_dim'],\n",
    "                out_dim=config['out_dim'],\n",
    "                device=config['device'],\n",
    "                implementation=config['implementation'],\n",
    "                connections=config['connections'],\n",
    "                grad_factor=config['grad_factor']       \n",
    "            )\n",
    "            layers.append(layer)\n",
    "            print(layer)\n",
    "        \n",
    "        self.logic_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.group = GroupSum(k=output_size, tau=tau)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the DiffLogic model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after processing through the logic layers and grouping operation.\n",
    "        \"\"\"\n",
    "        # Move tensor to GPU\n",
    "        if not isinstance(x, difflogic.PackBitsTensor):\n",
    "            # Move tensor to GPU only if it's not a PackBitsTensor\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.to('cuda')\n",
    "\n",
    "            # Flatten the input for non-PackBitsTensor\n",
    "            x = self.flatten(x)\n",
    "            \n",
    "        logits = self.logic_layers(x)\n",
    "        group = self.group(logits)\n",
    "        return group\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "        Initializes the Model, loads the DiffLogic model, sets up the optimizer, loss function, and other necessary configurations.\n",
    "\n",
    "        Args:\n",
    "            cfg (dict): Configuration dictionary containing model parameters such as layer configurations, output size, tau, and learning rate.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        layers_config = cfg[\"layers_config\"]\n",
    "        output_size = cfg[\"output_size\"]\n",
    "        tau = cfg[\"tau\"]\n",
    "                \n",
    "        self.diff_logic_model = DiffLogic(layers_config, output_size=output_size, tau=tau)\n",
    "        self.optimizer = torch.optim.Adam(self.diff_logic_model.parameters(), lr=cfg[\"learning_rate\"])\n",
    "        self.log_text = \"\"  # Initialize the logging string\n",
    "        self.data_batch = []\n",
    "        self.criterion = nn.CrossEntropyLoss() # loss function for classification tasks\n",
    "\n",
    "    def forward(self, prediction_dict):    \n",
    "        \"\"\"\n",
    "        Forward pass to predict the model output.\n",
    "\n",
    "        Args:\n",
    "            prediction_dict (dict): Dictionary containing input data for making predictions.\n",
    "\n",
    "        Returns:\n",
    "            None: Updates the prediction_dict with the predicted output data.\n",
    "        \"\"\"\n",
    "        input_data = prediction_dict[\"input_data\"]\n",
    "        output = self.diff_logic_model(input_data)\n",
    "        self.log_text += f\"State Prediction: {output}\\n\"\n",
    "        prediction_dict[\"pred_output_data\"] = output\n",
    "\n",
    "    def loss(self, prediction, label):\n",
    "        \"\"\"\n",
    "        Computes the loss between the predicted and true labels.\n",
    "\n",
    "        Args:\n",
    "            prediction (torch.Tensor): Predicted tensor output from the model.\n",
    "            label (torch.Tensor): True labels tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The computed loss value.\n",
    "        \"\"\"\n",
    "        return self.criterion(prediction, label)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Updates the model parameters by performing a single optimization step.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, tdata, mem, batch_size):\n",
    "        \"\"\"\n",
    "        Training method that returns the loss after receiving a batch of data.\n",
    "\n",
    "        Args:\n",
    "            tdata (any): Training data.\n",
    "            mem (any): Memory buffer or additional data needed for training.\n",
    "            batch_size (int): Size of the data batch for training.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The loss value for the batch.\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = torch.tensor([0.0 for i in range(batch_size)])\n",
    "        return loss\n",
    "\n",
    "    def test_train(self, prediction_dict):\n",
    "        \"\"\"\n",
    "        Training method for system development on a dummy dataset.\n",
    "\n",
    "        Args:\n",
    "            prediction_dict (dict): Dictionary containing predicted and true output data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The computed loss.\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(prediction_dict[\"pred_output_data\"], prediction_dict[\"true_output_data\"]).flatten()  # Structure loss (DNN relies on down-stream prediction)  \n",
    "        return loss\n",
    "\n",
    "    def save(self, file_path, model_name='model'):\n",
    "        \"\"\"\n",
    "        Saves the model's state dictionary to the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path where the model will be saved.\n",
    "            model_name (str): Name of the saved model\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.diff_logic_model.state_dict(),\n",
    "            'connections': [layer.indices for layer in self.diff_logic_model.logic_layers if isinstance(layer, LogicLayer)]\n",
    "        }, os.path.join(file_path, f\"{model_name}.pth\"))\n",
    "        self.log_text += f\"Model saved to: {file_path}\\n\"\n",
    "\n",
    "    def load(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the model's state dictionary from the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path from which the model will be loaded.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(file_path)\n",
    "        self.diff_logic_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Assign connections to each LogicLayer\n",
    "        for idx, layer in enumerate(self.diff_logic_model.logic_layers):\n",
    "            if isinstance(layer, LogicLayer):\n",
    "                layer.indices = checkpoint['connections'][idx]\n",
    "\n",
    "        self.diff_logic_model.eval()\n",
    "        self.log_text += f\"Model loaded from: {file_path}\\n\"\n",
    "\n",
    "    def get_accuracy(self, data_loader):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the model against a data loader\n",
    "        \n",
    "        Args:\n",
    "            data_loader: a DataLoader object, e.g. train_loader or test_loader\n",
    "            \n",
    "        Returns:\n",
    "            float: The accuracy\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        # Ensure model is in evaluation mode\n",
    "        self.diff_logic_model.eval()\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            for batch_inputs, batch_outputs in tqdm(data_loader, desc=\"Running Inference\"):\n",
    "                batch_inputs, batch_outputs = batch_inputs.to('cuda'), batch_outputs.to('cuda')\n",
    "\n",
    "                # Forward pass to get predictions\n",
    "                outputs = self.diff_logic_model(batch_inputs)\n",
    "\n",
    "                # Get the predicted class (index of the maximum logit)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Count correct predictions\n",
    "                total += batch_outputs.size(0)  # Total number of samples in the batch\n",
    "                correct += (predicted == batch_outputs).sum().item()  # Count correct predictions\n",
    "\n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa9f844-c392-4ced-9c49-e47dc8508f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"./../../../../mkunzlermaldaner/project/DIFFLOGIC/trained_models/trained_binary_models/binarized_model_077_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0e802-6cd8-49f9-bf73-ba3b2e5ea335",
   "metadata": {},
   "source": [
    "### MiniNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0556c-0dc4-4144-9b24-e7b10c85155f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fafb47c0-c884-4433-81e0-2d7ff9d1448b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogicLayer(400, 2500, train)\n",
      "LogicLayer(2500, 2500, train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:01<00:00, 18.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9237132352941176"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_name = 'model_077'\n",
    "model_name_config = model_name # from mnist_config.yaml\n",
    "model_name_weights = f'binarized_{model_name}_weights' # trained weights in model_name.pth\n",
    "trained_models_dir = './../../../../mkunzlermaldaner/project/DIFFLOGIC/trained_models/trained_binary_models'\n",
    "PATH = f'{trained_models_dir}/{model_name_weights}.pth'\n",
    "\n",
    "# ensure you have a \"mnist_config.yaml\" file within a \"config\" folder\n",
    "with initialize(version_base=None, config_path=\"config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"mnist_config_20x20\")\n",
    "\n",
    "# access the configuration for a specific model (e.g., model_000)\n",
    "model_cfg = cfg['models'][model_name_config]\n",
    "\n",
    "# instantiate the model and load its weights\n",
    "model = Model(model_cfg).to('cuda')\n",
    "model.load(PATH)\n",
    "# print(model)\n",
    "\n",
    "model.get_accuracy(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481f4d2e-6a6b-48f1-b38e-0684dbb4323c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_OPERATIONS Loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL_OPERATIONS Loaded\") if ALL_OPERATIONS else print(\"ALL_OPERATIONS not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dd0c01-4746-4a59-9dfc-76421622a872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from LogicGraph import * \n",
    "\n",
    "def get_connectome(g, output_node, num_layers=2):\n",
    "    \n",
    "    connectome     = []\n",
    "    children = list(g.predecessors(output_node))\n",
    "    \n",
    "    for l in range(num_layers):\n",
    "        layer_connections = {'input_size':0, 'output_size':0, 'connections':[], 'logic_gates':[]}\n",
    "        new_children = [] \n",
    "        for child_node in children: \n",
    "            \n",
    "            # Figure out this layer/output properties\n",
    "            child_gate = g.nodes[child_node][\"gate\"] \n",
    "\n",
    "            flagged = True if child_node in [\"HIGH\",\"LOW\"] else False\n",
    "            child_gate = \"one\" if child_node == \"HIGH\" else child_gate\n",
    "            child_gate = \"zero\" if child_node == \"LOW\" else child_gate\n",
    "\n",
    "            layer_connections[\"logic_gates\"].append(ALL_OPERATIONS.index(child_gate))\n",
    "            layer_connections[\"output_size\"] += 1\n",
    "            \n",
    "            # Figure out the input properties/new children\n",
    "            gate_inputs = list(g.predecessors(child_node))\n",
    "            ginputs = {\"a\":\"NA\", \"b\":\"NA\", \"empty\":\"NA\"} \n",
    "            for gate in gate_inputs: \n",
    "                if gate not in new_children and gate not in [\"HIGH\",\"LOW\"]:\n",
    "                    new_children.append(gate) \n",
    "                    layer_connections[\"input_size\"] += 1\n",
    "                \n",
    "                props     = g.get_edge_data(gate, child_node)\n",
    "                wire_type = props[\"ab\"] if \"ab\" in props.keys() else \"empty\"\n",
    "                ginputs[wire_type] = gate\n",
    "            \n",
    "            ginputs[\"a\"] = int(ginputs[\"a\"].split(\"_N\")[1]) if ginputs[\"a\"] != \"NA\" else np.nan\n",
    "            ginputs[\"b\"] = int(ginputs[\"b\"].split(\"_N\")[1]) if ginputs[\"b\"] != \"NA\" else np.nan\n",
    "            \n",
    "            layer_connections[\"connections\"].append((ginputs[\"a\"],ginputs[\"b\"]))\n",
    "            \n",
    "        # Figure out this layer/output properties\n",
    "        children = new_children\n",
    "        layer_connections[\"connections\"] = torch.tensor(layer_connections[\"connections\"])\n",
    "        layer_connections[\"connections\"] = torch.nan_to_num(layer_connections[\"connections\"],nan=torch.nanmedian(layer_connections[\"connections\"])).to(int) \n",
    "        connectome.append(layer_connections)\n",
    "        \n",
    "        # Renumber the entries \n",
    "        for k,dummy in enumerate(connectome): \n",
    "            unique = np.unique(dummy[\"connections\"])\n",
    "            for i,u in enumerate(unique): \n",
    "                connectome[k][\"connections\"][connectome[k][\"connections\"]==u] = i\n",
    "        \n",
    "    return connectome\n",
    "\n",
    "g = LogicGraph(model.diff_logic_model)\n",
    "\n",
    "connectomes = [] \n",
    "for i in range(10): \n",
    "    connectomes.append( get_connectome(g.g, f\"L3_N{i}\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76ebe8-3742-41c4-b9d4-51183cd222ec",
   "metadata": {},
   "source": [
    "##### Individual DataLoaders for each Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ff751f-6575-4af3-b679-a99f13e2c2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gets individual dataloaders for each digit\n",
    "digit_loaders = {digit: DataLoader(\n",
    "    [sample for sample in train_loader.dataset if sample[1] == digit],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ") for digit in range(10)} \n",
    "\n",
    "# you can access loaders like this:\n",
    "digit1loader = digit_loaders[1]\n",
    "digit4loader = digit_loaders[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed39eb6-dd19-4a85-b7a8-35fc03221516",
   "metadata": {},
   "source": [
    "##### Ensures Neurons in Deeper Layers do Not reference unexistent nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171498ac-91d8-4ddf-8ca8-8475a76caa76",
   "metadata": {},
   "source": [
    "##### Mapping Logic Gates to Integer Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2beaf602-8ff9-4386-9857-b4d6043215db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculation given two inputs (a and b) and their logic gate (i)\n",
    "def bin_op(a, b, i):\n",
    "    assert a[0].shape == b[0].shape, (a[0].shape, b[0].shape)\n",
    "    if a.shape[0] > 1:\n",
    "        assert a[1].shape == b[1].shape, (a[1].shape, b[1].shape)\n",
    "\n",
    "    if i == 0:\n",
    "        return torch.zeros_like(a)\n",
    "    elif i == 1:\n",
    "        return a * b\n",
    "    elif i == 2:\n",
    "        return a - a * b\n",
    "    elif i == 3:\n",
    "        return a\n",
    "    elif i == 4:\n",
    "        return b - a * b\n",
    "    elif i == 5:\n",
    "        return b\n",
    "    elif i == 6:\n",
    "        return a + b - 2 * a * b\n",
    "    elif i == 7:\n",
    "        return a + b - a * b\n",
    "    elif i == 8:\n",
    "        return 1 - (a + b - a * b)\n",
    "    elif i == 9:\n",
    "        return 1 - (a + b - 2 * a * b)\n",
    "    elif i == 10:\n",
    "        return 1 - b\n",
    "    elif i == 11:\n",
    "        return 1 - b + a * b\n",
    "    elif i == 12:\n",
    "        return 1 - a\n",
    "    elif i == 13:\n",
    "        return 1 - a + a * b\n",
    "    elif i == 14:\n",
    "        return 1 - a * b\n",
    "    elif i == 15:\n",
    "        return torch.ones_like(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f682d-d854-407e-a027-c9dabff1965b",
   "metadata": {},
   "source": [
    "##### Custom DiffLogic Declaration for Reduced Model Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5019d6f4-b7c2-484f-bbdb-4c965c454b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from difflogic.packbitstensor import PackBitsTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8308ff5-ec29-412d-b79d-b19972f6601f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import difflogic_cuda\n",
    "class LogicLayerCudaFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, a, b, w, given_x_indices_of_y_start, given_x_indices_of_y):\n",
    "        ctx.save_for_backward(x, a, b, w, given_x_indices_of_y_start, given_x_indices_of_y)\n",
    "        return difflogic_cuda.forward(x, a, b, w)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y):\n",
    "        x, a, b, w, given_x_indices_of_y_start, given_x_indices_of_y = ctx.saved_tensors\n",
    "        grad_y = grad_y.contiguous()\n",
    "\n",
    "        grad_w = grad_x = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_x = difflogic_cuda.backward_x(x, a, b, w, grad_y, given_x_indices_of_y_start, given_x_indices_of_y)\n",
    "        if ctx.needs_input_grad[3]:\n",
    "            grad_w = difflogic_cuda.backward_w(x, a, b, grad_y)\n",
    "        return grad_x, None, None, grad_w, None, None, None\n",
    "\n",
    "\n",
    "# modify CustomLogicLayer to use bin_op\n",
    "class CustomLogicLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        connections: torch.Tensor,  # manually passed connections\n",
    "        logic_gates: list,          \n",
    "        device: str = 'cuda',\n",
    "        grad_factor: float = 1.,\n",
    "        implementation: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # use predefined logic gates and connections if provided\n",
    "        connections = tuple([torch.tensor(t).to(device) for t in connections.T.cpu().detach().numpy()])\n",
    "        print(connections)\n",
    "        self.indices = connections\n",
    "        self.logic_gates = logic_gates\n",
    "        self.weights = torch.nn.parameter.Parameter(torch.randn(out_dim, 16, device=device))\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.device = device\n",
    "        self.grad_factor = grad_factor\n",
    "        \n",
    "        self.implementation = implementation\n",
    "        if self.implementation is None and device == 'cuda':\n",
    "            self.implementation = 'cuda'\n",
    "        elif self.implementation is None and device == 'cpu':\n",
    "            self.implementation = 'python'\n",
    "        assert self.implementation in ['cuda', 'python'], self.implementation\n",
    "        \n",
    "        if self.implementation == 'cuda':\n",
    "            \"\"\"\n",
    "            Defining additional indices for improving the efficiency of the backward of the CUDA implementation.\n",
    "            \"\"\"\n",
    "            given_x_indices_of_y = [[] for _ in range(in_dim)]\n",
    "            indices_0_np = self.indices[0].cpu().numpy()\n",
    "            indices_1_np = self.indices[1].cpu().numpy()\n",
    "            for y in range(out_dim):\n",
    "                given_x_indices_of_y[indices_0_np[y]].append(y)\n",
    "                given_x_indices_of_y[indices_1_np[y]].append(y)\n",
    "            self.given_x_indices_of_y_start = torch.tensor(\n",
    "                np.array([0] + [len(g) for g in given_x_indices_of_y]).cumsum(), device=device, dtype=torch.int64)\n",
    "            self.given_x_indices_of_y = torch.tensor(\n",
    "                [item for sublist in given_x_indices_of_y for item in sublist], dtype=torch.int64, device=device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, PackBitsTensor):\n",
    "            assert not self.training, 'PackBitsTensor is not supported for the differentiable training mode.'\n",
    "            assert self.device == 'cuda', 'PackBitsTensor is only supported for CUDA, not for {}. ' \\\n",
    "                                          'If you want fast inference on CPU, please use CompiledDiffLogicModel.' \\\n",
    "                                          ''.format(self.device)\n",
    "        else:\n",
    "            if self.grad_factor != 1.:\n",
    "                x = GradFactor.apply(x, self.grad_factor)\n",
    "\n",
    "        if self.implementation == 'cuda':\n",
    "            if isinstance(x, PackBitsTensor):\n",
    "                return self.forward_cuda_eval(x)\n",
    "            return self.forward_cuda(x)\n",
    "        elif self.implementation == 'python':\n",
    "            return self.forward_python(x)\n",
    "        else:\n",
    "            raise ValueError(self.implementation)\n",
    "            \n",
    "    def forward_python(self, x):\n",
    "        assert x.shape[-1] == self.in_dim, (x[0].shape[-1], self.in_dim)\n",
    "\n",
    "        if self.indices[0].dtype == torch.int64 or self.indices[1].dtype == torch.int64:\n",
    "            print(self.indices[0].dtype, self.indices[1].dtype)\n",
    "            self.indices = self.indices[0].long(), self.indices[1].long()\n",
    "            print(self.indices[0].dtype, self.indices[1].dtype)\n",
    "\n",
    "        a, b = x[..., self.indices[0]], x[..., self.indices[1]]\n",
    "        if self.training:\n",
    "            x = bin_op_s(a, b, torch.nn.functional.softmax(self.weights, dim=-1))\n",
    "        else:\n",
    "            weights = torch.nn.functional.one_hot(self.weights.argmax(-1), 16).to(torch.float32)\n",
    "            x = bin_op_s(a, b, weights)\n",
    "        return x\n",
    "\n",
    "        \n",
    "#    def forward(self, x):\n",
    "#        assert x.shape[-1] == self.in_dim, (x.shape[-1], self.in_dim)\n",
    "#        # x: shape (batch_size, in_dim)\n",
    "#        # self.indices: tensor of shape (out_dim, 2)\n",
    "#        # Indices must be within [0, in_dim - 1]#\n",
    "#\n",
    "#        a = x[:, self.indices[:, 0]]  # shape (batch_size, out_dim)\n",
    "#        b = x[:, self.indices[:, 1]]  # shape (batch_size, out_dim)\n",
    "#        outputs = torch.zeros(x.shape[0], self.out_dim, device=self.device)\n",
    "\n",
    "#        for neuron_idx, gate_idx in enumerate(self.logic_gates):\n",
    "#            result = bin_op(a[:, neuron_idx], b[:, neuron_idx], gate_idx)\n",
    "#            outputs[:, neuron_idx] = result\n",
    "\n",
    "#        return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward_cuda(self, x):\n",
    "        if self.training:\n",
    "            assert x.device.type == 'cuda', x.device\n",
    "        assert x.ndim == 2, x.ndim\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        x = x.contiguous()\n",
    "\n",
    "        assert x.shape[0] == self.in_dim, (x.shape, self.in_dim)\n",
    "\n",
    "        a, b = self.indices\n",
    "\n",
    "        if self.training:\n",
    "            w = torch.nn.functional.softmax(self.weights, dim=-1).to(x.dtype)\n",
    "            return LogicLayerCudaFunction.apply(\n",
    "                x, a, b, w, self.given_x_indices_of_y_start, self.given_x_indices_of_y\n",
    "            ).transpose(0, 1)\n",
    "        else:\n",
    "            w = torch.nn.functional.one_hot(self.weights.argmax(-1), 16).to(x.dtype)\n",
    "            with torch.no_grad():\n",
    "                return LogicLayerCudaFunction.apply(\n",
    "                    x, a, b, w, self.given_x_indices_of_y_start, self.given_x_indices_of_y\n",
    "                ).transpose(0, 1)\n",
    "\n",
    "    def forward_cuda_eval(self, x: PackBitsTensor):\n",
    "        \"\"\"\n",
    "        WARNING: this is an in-place operation.\n",
    "\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert not self.training\n",
    "        assert isinstance(x, PackBitsTensor)\n",
    "        assert x.t.shape[0] == self.in_dim, (x.t.shape, self.in_dim)\n",
    "\n",
    "        a, b = self.indices\n",
    "        w = self.weights.argmax(-1).to(torch.uint8)\n",
    "        x.t = difflogic_cuda.eval(x.t, a, b, w)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # overloading function \n",
    "    def extra_repr(self):\n",
    "        return '{}, {}, {}'.format(self.in_dim, self.out_dim, 'train' if self.training else 'eval')\n",
    "    \n",
    "# defines custom logic network which accepts predefined connections and gates\n",
    "class CustomDiffLogic(nn.Module):\n",
    "    def __init__(self, layer_specs, output_size, device='cuda', tau=30):\n",
    "        \"\"\"\n",
    "        Constructs a network using layers of logic gates and custom connections.\n",
    "\n",
    "        Args:\n",
    "        layer_specs (list): List of layer specifications, each containing\n",
    "                            input size, output size, connections, and logic gates.\n",
    "        device (str): Device for computation (e.g., 'cuda' or 'cpu').\n",
    "        \"\"\"\n",
    "        super(CustomDiffLogic, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.device = device\n",
    "        \n",
    "        layers = []\n",
    "        # creates each layer with specific connections and logic gates\n",
    "        for layer_spec in layer_specs:\n",
    "            layer = CustomLogicLayer(\n",
    "                in_dim=layer_spec['input_size'],\n",
    "                out_dim=layer_spec['output_size'],\n",
    "                device=self.device,\n",
    "                connections=layer_spec['connections'],\n",
    "                logic_gates=layer_spec['logic_gates'],\n",
    "            )\n",
    "            layers.append(layer)\n",
    "    \n",
    "        self.logic_layers = nn.Sequential(*layers)\n",
    "        self.group = GroupSum(k=output_size, tau=tau)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # uses cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to('cuda')    \n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        logits = self.logic_layers(x)\n",
    "        #group = self.group(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec53d53-8349-44ba-b990-c45a1bcc81b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, layer_specs, output_size=10, tau=30, lr=0.1):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.tau = tau\n",
    "        self.lr = lr        \n",
    "            \n",
    "        self.custom_diff_logic_model = CustomDiffLogic(layer_specs, output_size=self.output_size, tau=self.tau)\n",
    "        params = list(self.custom_diff_logic_model.parameters())\n",
    "        #print(params)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(params, lr=self.lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()  # Loss function for classification tasks\n",
    "\n",
    "    def forward(self, input_data):    \n",
    "        \"\"\"\n",
    "        Forward pass to predict the model output.\n",
    "        Args:\n",
    "            input_data (torch.Tensor): Input tensor for prediction.\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions.\n",
    "        \"\"\"\n",
    "        return self.custom_diff_logic_model(input_data)\n",
    "\n",
    "    def loss(self, prediction, label):\n",
    "        \"\"\"\n",
    "        Computes the loss between the predicted and true labels.\n",
    "        Args:\n",
    "            prediction (torch.Tensor): Predicted tensor output from the model.\n",
    "            label (torch.Tensor): True labels tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: The computed loss value.\n",
    "        \"\"\"\n",
    "        return self.criterion(prediction, label)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Updates the model parameters by performing a single optimization step.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train_step(self, train_loader):\n",
    "        \"\"\"\n",
    "        Single training step for a batch of data.\n",
    "        Args:\n",
    "            train_loader: DataLoader for training.\n",
    "        Returns:\n",
    "            float: The average training loss for the batch.\n",
    "        \"\"\"\n",
    "        self.custom_diff_logic_model.train()  # Set model to training mode\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "            batch_inputs, batch_labels = batch_inputs.to('cuda'), batch_labels.to('cuda')\n",
    "            self.optimizer.zero_grad()  # Zero gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.forward(batch_inputs)\n",
    "            loss = self.loss(outputs, batch_labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()  # Compute gradients\n",
    "            self.step()      # Update model weights\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        return avg_loss\n",
    "\n",
    "    def test_train(self, train_loader):\n",
    "        \"\"\"\n",
    "        Testing/validation on a dataset without backpropagation.\n",
    "        Args:\n",
    "            train_loader: DataLoader for testing/validation.\n",
    "        Returns:\n",
    "            float: The average loss for the test set.\n",
    "        \"\"\"\n",
    "        self.custom_diff_logic_model.eval()  # Set model to evaluation mode\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_labels in train_loader:\n",
    "                batch_inputs, batch_labels = batch_inputs.to('cuda'), batch_labels.to('cuda')\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.forward(batch_inputs)\n",
    "                loss = self.loss(outputs, batch_labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        return avg_loss\n",
    "\n",
    "    def save(self, file_path, model_name='model'):\n",
    "        \"\"\"\n",
    "        Saves the model's state dictionary to the specified file path.\n",
    "        Args:\n",
    "            file_path (str): Path where the model will be saved.\n",
    "            model_name (str): Name of the saved model\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.custom_diff_logic_model.state_dict(),\n",
    "            'connections': [layer.indices for layer in self.custom_diff_logic_model.logic_layers if isinstance(layer, CustomLogicLayer)]\n",
    "        }, os.path.join(file_path, f\"{model_name}.pth\"))\n",
    "\n",
    "    def load(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the model's state dictionary from the specified file path.\n",
    "        Args:\n",
    "            file_path (str): Path from which the model will be loaded.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(file_path)\n",
    "        self.custom_diff_logic_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Assign connections to each LogicLayer\n",
    "        for idx, layer in enumerate(self.custom_diff_logic_model.logic_layers):\n",
    "            if isinstance(layer, CustomLogicLayer):\n",
    "                layer.indices = checkpoint['connections'][idx]\n",
    "\n",
    "        self.custom_diff_logic_model.eval()\n",
    "\n",
    "    def get_accuracy(self, data_loader):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the model against a data loader.\n",
    "        Args:\n",
    "            data_loader: a DataLoader object, e.g. train_loader or test_loader.\n",
    "        Returns:\n",
    "            float: The accuracy.\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        self.custom_diff_logic_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            for batch_inputs, batch_labels in tqdm(data_loader, desc=\"Running Inference\"):\n",
    "                batch_inputs, batch_labels = batch_inputs.to('cuda'), batch_labels.to('cuda')\n",
    "\n",
    "                # Forward pass to get predictions\n",
    "                outputs = self.custom_diff_logic_model(batch_inputs)\n",
    "\n",
    "                # Get the predicted class (index of the maximum logit)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Count correct predictions\n",
    "                total += batch_labels.size(0)  # Total number of samples in the batch\n",
    "                correct += (predicted == batch_labels).sum().item()  # Count correct predictions\n",
    "\n",
    "        accuracy = correct / total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60f623-ed9d-4c50-9b0e-f3676e872ae0",
   "metadata": {},
   "source": [
    "##### Pads the Last Layer so it is Divisible by the Number of Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00223e6-91c8-4c60-b9e4-c237412bcb9f",
   "metadata": {},
   "source": [
    "##### Putting it All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f8ca0e-8164-4584-a61a-d79b6c754787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 31, 216, 218,  63, 147, 381, 265, 222,  42,  38, 246, 401, 372,  94,\n",
      "        338, 342, 419, 179, 106, 170, 216,   7, 141, 385,  53, 259, 132, 159,\n",
      "        263, 130, 214, 430, 253, 271, 402, 256, 357, 122, 247,  18, 195, 139,\n",
      "         50, 308, 224, 216, 216,  74, 420, 110, 216, 262, 194, 154,  41, 251,\n",
      "         91, 196, 413, 216,  67, 417,  86, 343, 216,  54, 325, 270, 405, 421,\n",
      "         79, 244, 334, 150, 216, 278,  60,  93, 174, 306, 299, 173, 324,  95,\n",
      "         27, 337, 260, 107, 237, 332,  12, 406, 165, 127, 216, 281, 416,  73,\n",
      "         89, 226, 205, 370,   3, 164, 317, 380,  39, 248,  66, 301, 410, 252,\n",
      "        318, 201, 137, 204, 202, 305, 354,  19, 411, 216, 296, 117,   4, 424,\n",
      "        288, 369, 316, 422, 182, 150,  49, 223,  55,   9, 348,  52,  99, 216,\n",
      "        384, 353, 329, 135, 418,  14, 267, 216, 289, 350, 273, 379, 304, 216,\n",
      "        131, 216, 159, 425, 104, 406, 109, 198, 216, 331, 254, 216, 216, 169,\n",
      "        186, 125, 216, 216, 161, 429, 403, 148, 106, 200, 225,  16, 371, 206,\n",
      "        335, 391, 216,  59, 189,   1,   0,  62, 199, 395, 275,  78,  48, 297,\n",
      "        357, 120, 128, 229, 349,  21, 180, 390, 403,  84,  29, 314, 393, 294,\n",
      "        216, 138, 234, 136, 307,  68,  76, 321,  70, 383, 216, 374, 216, 216,\n",
      "         65, 216,   8, 146, 386, 358, 315, 242,  46, 171, 411, 166, 266, 408,\n",
      "        376, 362, 217, 240, 258, 216,  13, 119,  69, 404, 373, 231],\n",
      "       device='cuda:0'), tensor([197, 388, 185, 102, 323,  46, 216, 216,  20,  90, 364,  97, 269, 420,\n",
      "        330, 310, 268,  45, 158, 427, 216, 184, 268,  40,  61, 133,  15, 213,\n",
      "        414, 389, 216, 339, 162, 300, 286, 168, 426, 409, 221, 101, 216,  44,\n",
      "        216, 111,  96, 215, 241, 337,  28, 415, 365, 145,  81,  15, 249, 160,\n",
      "        360, 144, 216, 243, 238,  87, 377, 185, 394,  23, 428, 345,  26, 170,\n",
      "        266,  96, 285, 176,  24, 188, 227,  22, 245,  82, 233, 255,  72, 216,\n",
      "         36, 363, 257, 149, 220, 326, 400,   2, 264, 163, 361,  10, 177,  25,\n",
      "        276, 396, 129, 239,  80, 290, 347, 303, 191,  30, 112, 423, 216, 172,\n",
      "        292, 293, 175, 311,  47, 103, 203, 388, 392, 216, 344, 155, 410, 143,\n",
      "         32, 367,  17, 291, 328, 284, 279, 250, 187, 378,  98, 319, 309, 216,\n",
      "        232, 228, 261,   5, 302, 105, 272, 116, 210,  55, 152, 322, 151, 124,\n",
      "        216,  35, 123, 115, 207,  85, 190, 236, 212,  64, 235, 216, 312, 399,\n",
      "        183, 333, 407, 327, 256, 397, 359, 390, 368, 216, 295, 208, 387, 187,\n",
      "         34,  56, 274,  51, 216, 313,  75, 356, 191,  88, 114, 431, 355, 382,\n",
      "        108, 280,  77,  83, 351,  37, 193, 397, 230,   6, 352, 121, 412, 142,\n",
      "        216, 156, 209, 192, 298, 181, 341, 216, 283, 346, 287,  33,  43, 282,\n",
      "        277,  11,  98, 211,  71, 118, 100, 126, 113, 178, 157, 320, 167, 140,\n",
      "        398,  92, 336, 381, 219, 366,  58, 340, 134, 375, 153,  57],\n",
      "       device='cuda:0'))\n",
      "(tensor([320, 240, 115, 184, 299, 100,  95, 167,   2, 241,   1, 343, 160,  46,\n",
      "        188,  56,  18, 113,  82, 326,  20, 167, 318, 123, 329, 278, 156, 167,\n",
      "         99, 217, 174, 239, 167, 132, 284, 125, 167, 172, 255, 134,  32, 152,\n",
      "        127, 167, 167, 167,  18, 256, 122, 167, 106, 215, 333,  59, 167, 175,\n",
      "         30,  23, 138, 189, 142, 283, 167,  86, 266, 235, 167,  83, 163, 205,\n",
      "        143, 105, 298,  91, 277,  58, 198,  28, 167, 167, 227, 160, 187, 261,\n",
      "        167, 250, 219,  71,  82, 106, 167,  96, 136, 285, 223,  61, 167, 141,\n",
      "        288, 167, 119, 102, 278, 201, 261, 235,  45, 322, 123, 189, 158,   9,\n",
      "        264, 188,  91, 337, 103, 293, 163,  22, 120, 270, 323, 187, 167, 130,\n",
      "        318, 107, 194, 226, 125, 344, 167, 202, 342, 304, 246,  60,  76, 288,\n",
      "        167, 138, 167, 302, 299, 210, 321,  24,  44,   5, 324,  88,  93,  87,\n",
      "        111,  33, 167, 139, 213, 296, 204, 296, 259, 238, 234, 124, 135, 145,\n",
      "         92,  81, 136, 237, 238, 164, 113, 251,  88, 163,  48, 169,  66, 328,\n",
      "        167,  73, 111, 264, 313,  34, 331, 148, 167, 286, 308, 153, 209, 179,\n",
      "        149, 167,  19, 281, 282, 258, 167,  88, 322, 346,  88, 191, 167, 155,\n",
      "        252, 214, 123, 339, 224, 167, 325, 167, 193,  14, 154, 233, 250, 148,\n",
      "        167,  63,  89,  67, 177, 267, 109, 326, 167,  22, 216, 283, 200, 331,\n",
      "        313, 202, 148, 167, 196, 245, 167,  71, 225, 167, 136, 112,  51,  84,\n",
      "        294, 142, 175, 167, 167,  55, 194, 289, 204, 188,  46,  38, 201,  79,\n",
      "        167, 190, 291, 167,  95, 323, 249,  13, 301,  28, 195, 172, 217,  97,\n",
      "        112, 268, 167, 175,  73,  41, 154, 233, 348,   3, 167, 232, 111, 259,\n",
      "        167, 183,  89,  28,  55,  94, 172, 299,  17, 206,  97,  12,  64, 108,\n",
      "        294, 283, 110, 157,  42, 251, 144, 288, 167,   4, 261, 183, 128, 167,\n",
      "        227, 167, 176, 284,  60, 167, 186, 214,  25,  92, 108, 274,  63, 141,\n",
      "        314,  97, 343,  41, 257, 264, 129, 275, 102, 167,  59, 151, 144, 104,\n",
      "        253, 127,  83,  34, 182, 133, 124, 326, 289,  15, 126, 221,   0, 321,\n",
      "        160,  35, 117, 263,  94, 155, 239, 332, 278,  36, 304, 167, 136, 167,\n",
      "        277, 158, 310,   4, 160, 238, 327,   3, 243, 167, 113, 109, 165, 218,\n",
      "         31, 323, 291, 223, 167, 248, 167, 207, 135, 167, 167, 167,  60, 167,\n",
      "         40,  10, 158, 196,  50, 212, 118, 217, 173, 167, 171, 209, 114,  27,\n",
      "        167, 273,  50,   1,   0, 262, 269, 167, 115, 167, 170, 167],\n",
      "       device='cuda:0'), tensor([187,  90,  42, 105,  64, 137, 120,  79,  72, 212,   8, 293, 322, 167,\n",
      "        190, 231,  85, 162, 274, 200, 326, 167, 275, 167, 167, 102,  93,  44,\n",
      "        167, 167, 167, 167, 226,  26, 167, 211, 167, 291, 167, 226, 276, 167,\n",
      "        167,  12, 305, 190, 298, 208, 296, 167, 161,  39, 301, 132, 169,  62,\n",
      "        230,   6, 252, 167, 348,  27,  56, 167, 281, 271, 161, 167, 156, 224,\n",
      "         67, 348, 189, 119, 261, 228, 265, 272,  36, 312, 162,  23, 153, 309,\n",
      "          8, 167, 167,   0, 167, 257, 104, 167, 217, 236,  32,  52,  30, 246,\n",
      "        175, 318, 131, 271, 139,  59, 268,  33, 146,  78, 222, 167,   7,  70,\n",
      "         70, 200, 262, 167,  47, 220, 167, 271, 167, 319,  47, 185, 167, 339,\n",
      "         86, 167,  13,  78, 340, 258, 287, 167, 236, 248, 167,  62, 309,  50,\n",
      "         70, 167, 167, 307, 200,  24, 305,  68, 167, 227, 112, 127, 292, 186,\n",
      "        165, 201,  76, 167,  54, 175, 312, 306, 204, 266, 167, 105, 222,  61,\n",
      "         16, 316, 148,  87, 299, 247, 300, 167, 254, 167, 167, 167, 253, 349,\n",
      "        149, 242, 322, 295, 167,  21,  96, 265,  75,  37,  79, 167,  17, 173,\n",
      "        262, 167, 310,   2, 297, 266, 166, 279, 167, 101, 285,  91,  30,  98,\n",
      "        211, 244, 167,  64,   7, 279, 167, 116, 121,  25,  96,  34,  31, 311,\n",
      "         60,  24, 143, 167,  69, 340,  93, 214, 150, 319,  74,  77, 138,  85,\n",
      "        199, 222, 345, 222,   6, 181,  28, 213, 107,  40, 234, 288, 167, 285,\n",
      "         17, 167, 288,   3,  96, 167,   1, 250, 167, 274, 159, 167, 167, 157,\n",
      "        150, 189,  58, 307, 167, 167,   9, 335, 129, 167, 120, 291, 234,  61,\n",
      "        346, 260, 280, 178, 167,  55, 203, 165, 324, 205,  29, 167,  26, 167,\n",
      "         43, 262,  67, 303, 344,  63, 167, 167, 226, 167, 152, 167, 293, 296,\n",
      "        256,  26, 286, 167, 167, 340, 233, 149, 167,  81, 189, 336,  59,  41,\n",
      "        167, 134,   7, 167,  65, 180, 167, 330, 167, 167,  16,  49, 133, 321,\n",
      "        167,  10,  90, 167, 167,  57, 197, 270, 168, 166, 125,   5, 132,  37,\n",
      "         21, 277,  21, 167,  56, 349, 167, 317,  68, 203, 167, 220, 243, 245,\n",
      "        341,  80, 167, 125, 231, 328,  21, 175, 308, 313, 167, 279, 167, 269,\n",
      "         67,  74, 208, 167, 127, 292, 167, 115, 250,  76, 128,  27, 269, 340,\n",
      "        167,  73, 347, 338,  32, 289,  11, 140, 192,  37, 254, 290,  39, 315,\n",
      "         89, 334, 300, 115, 268,  53, 178, 167, 167, 122, 278, 167, 167, 147,\n",
      "        167, 306, 142, 111, 229, 101, 167, 319, 167, 117, 167, 144],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "connections = tuple([torch.tensor(t).to(\"cpu\") for t in connectome[0][\"connections\"].T.cpu().detach().numpy()])\n",
    "custom_model = CustomModel(connectome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5933b247-7868-4be9-9546-a6f1b40f5536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (custom_diff_logic_model): CustomDiffLogic(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (logic_layers): Sequential(\n",
       "      (0): CustomLogicLayer(432, 250, train)\n",
       "      (1): CustomLogicLayer(350, 432, train)\n",
       "    )\n",
       "    (group): GroupSum(k=10, tau=30)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1f10790-75b2-4df3-9638-07ef85013cad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_size': 400,\n",
       "  'output_size': 71,\n",
       "  'connections': tensor([[303, 179],\n",
       "          [199, 291],\n",
       "          [ 85, 143],\n",
       "          [257, 397],\n",
       "          [385, 175],\n",
       "          [339, 220],\n",
       "          [125, 393],\n",
       "          [158,  20],\n",
       "          [109,  22],\n",
       "          [139, 369],\n",
       "          [219, 266],\n",
       "          [311, 220],\n",
       "          [279, 183],\n",
       "          [241, 111],\n",
       "          [240,  16],\n",
       "          [139, 200],\n",
       "          [198, 319],\n",
       "          [108, 201],\n",
       "          [122, 330],\n",
       "          [ 76,  20],\n",
       "          [198,   0],\n",
       "          [251, 343],\n",
       "          [357, 315],\n",
       "          [398, 276],\n",
       "          [180,  41],\n",
       "          [ 83, 104],\n",
       "          [279, 139],\n",
       "          [259, 277],\n",
       "          [219, 159],\n",
       "          [309, 158],\n",
       "          [ 22, 280],\n",
       "          [231, 217],\n",
       "          [330, 178],\n",
       "          [130, 121],\n",
       "          [  1, 237],\n",
       "          [331, 200],\n",
       "          [268, 272],\n",
       "          [177, 345],\n",
       "          [240, 219],\n",
       "          [257, 109],\n",
       "          [310, 133],\n",
       "          [238,  99],\n",
       "          [398, 396],\n",
       "          [326,  96],\n",
       "          [218, 290],\n",
       "          [280, 297],\n",
       "          [140, 200],\n",
       "          [110, 384],\n",
       "          [200, 180],\n",
       "          [232, 382],\n",
       "          [354, 229],\n",
       "          [364,  17],\n",
       "          [221, 372],\n",
       "          [248, 278],\n",
       "          [260, 372],\n",
       "          [344, 260],\n",
       "          [129, 344],\n",
       "          [257, 188],\n",
       "          [296,   7],\n",
       "          [173, 319],\n",
       "          [142, 313],\n",
       "          [161,  80],\n",
       "          [199, 331],\n",
       "          [  1,  80],\n",
       "          [189, 196],\n",
       "          [ 98, 154],\n",
       "          [218, 247],\n",
       "          [ 21,   7],\n",
       "          [242, 338],\n",
       "          [220, 177],\n",
       "          [241, 227]], device='cuda:0'),\n",
       "  'logic_gates': [13,\n",
       "   12,\n",
       "   7,\n",
       "   15,\n",
       "   15,\n",
       "   11,\n",
       "   15,\n",
       "   8,\n",
       "   15,\n",
       "   12,\n",
       "   13,\n",
       "   4,\n",
       "   13,\n",
       "   12,\n",
       "   12,\n",
       "   11,\n",
       "   12,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   8,\n",
       "   3,\n",
       "   15,\n",
       "   4,\n",
       "   11,\n",
       "   15,\n",
       "   10,\n",
       "   9,\n",
       "   12,\n",
       "   3,\n",
       "   10,\n",
       "   15,\n",
       "   10,\n",
       "   12,\n",
       "   10,\n",
       "   11,\n",
       "   15,\n",
       "   12,\n",
       "   8,\n",
       "   14,\n",
       "   10,\n",
       "   12,\n",
       "   15,\n",
       "   15,\n",
       "   12,\n",
       "   12,\n",
       "   15,\n",
       "   15,\n",
       "   12,\n",
       "   15,\n",
       "   5,\n",
       "   12,\n",
       "   14,\n",
       "   14,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   13,\n",
       "   15,\n",
       "   15,\n",
       "   15,\n",
       "   11,\n",
       "   12,\n",
       "   11,\n",
       "   11,\n",
       "   13,\n",
       "   2,\n",
       "   7,\n",
       "   14,\n",
       "   12,\n",
       "   12]},\n",
       " {'input_size': 71,\n",
       "  'output_size': 10,\n",
       "  'connections': tensor([[67, 27],\n",
       "          [16, 50],\n",
       "          [63,  2],\n",
       "          [11, 66],\n",
       "          [21, 33],\n",
       "          [ 0, 40],\n",
       "          [23, 29],\n",
       "          [51, 24],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0]], device='cuda:0'),\n",
       "  'logic_gates': [5, 3, 3, 10, 15, 15, 12, 15, 0, 0]}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7740740f-4327-40ec-86b4-1b8f6f14e79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (custom_diff_logic_model): CustomDiffLogic(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (logic_layers): Sequential(\n",
       "      (0): CustomLogicLayer(400, 71, train)\n",
       "      (1): CustomLogicLayer(71, 10, train)\n",
       "    )\n",
       "    (group): GroupSum(k=10, tau=30)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our reduced model architecture\n",
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "14f8b60c-0859-419e-aa8f-71bca429bdce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (diff_logic_model): DiffLogic(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (logic_layers): Sequential(\n",
       "      (0): LogicLayer(400, 2500, train)\n",
       "      (1): LogicLayer(2500, 2500, train)\n",
       "    )\n",
       "    (group): GroupSum(k=10, tau=10)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the overall model architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad6fbc-f66b-4eca-8bc9-d89677bb57db",
   "metadata": {},
   "source": [
    "##### WHERE I AM CURRENTLY STUCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3a858e7d-dcbe-48c2-b042-4d32d674eae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (custom_diff_logic_model): CustomDiffLogic(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (logic_layers): Sequential(\n",
       "      (0): CustomLogicLayer(400, 2500, train)\n",
       "      (1): CustomLogicLayer(2500, 2500, train)\n",
       "    )\n",
       "    (group): GroupSum(k=10, tau=30)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "43fddcda-6a75-4e6b-84df-d51fb09d64b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-0 :  4.00543212890625e-05\n",
      "test-1 :  0.020060300827026367\n",
      "test-2 :  0.02005743980407715\n",
      "test-3 :  0.020055532455444336\n",
      "test-4 :  0.020055532455444336\n",
      "test-5 :  0.020055294036865234\n",
      "test-6 :  0.020055770874023438\n",
      "test-7 :  0.020056962966918945\n",
      "test-8 :  0.02005457878112793\n",
      "test-9 :  0.020053625106811523\n"
     ]
    }
   ],
   "source": [
    "class Timer: \n",
    "    def __init__(self): \n",
    "        self.times = [time.time()] \n",
    "        self.diffs = [] \n",
    "        self.labels = [] \n",
    "        \n",
    "    def log(self,label = None): \n",
    "        self.times.append(time.time()) \n",
    "        self.diffs.append(self.times[-1] - self.times[-2]) \n",
    "        self.labels.append(label)\n",
    "\n",
    "    def print(self): \n",
    "        for i,label in enumerate(self.labels): \n",
    "            if label: \n",
    "                print(label,\": \", self.diffs[i])\n",
    "            else: \n",
    "                print(i,\": \", self.diffs[i])\n",
    "timer = Timer() \n",
    "for i in range(10):  \n",
    "    timer.log(f\"test-{i}\")\n",
    "    time.sleep(0.02)\n",
    "timer.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "19903e0c-a16b-47c4-ad45-78d3dc93f6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent model analysis\n",
      "M1 s  :  1.8596649169921875e-05\n",
      "M1 FL :  0.0001506805419921875\n",
      "M1 L1 :  0.000446319580078125\n",
      "M1 L2 :  0.00024318695068359375\n",
      "Custom model analysis\n",
      "M1 s  :  1.6450881958007812e-05\n",
      "M1 FL :  4.935264587402344e-05\n",
      "M1 L1 :  0.00019168853759765625\n",
      "M1 L2 :  0.0001747608184814453\n"
     ]
    }
   ],
   "source": [
    "print(\"Parent model analysis\")\n",
    "m1 = model.diff_logic_model\n",
    "mtime_pre = time.time()\n",
    "timer = Timer() \n",
    "timer.log(\"M1 s \")\n",
    "x1 = m1.flatten(sample)\n",
    "timer.log(\"M1 FL\")\n",
    "x2 = m1.logic_layers[0](x1)\n",
    "timer.log(\"M1 L1\")\n",
    "x3 = m1.logic_layers[1](x2)\n",
    "timer.log(\"M1 L2\")\n",
    "timer.print()\n",
    "\n",
    "print(\"Custom model analysis\")\n",
    "m2 = custom_model.custom_diff_logic_model\n",
    "mtime_pre = time.time()\n",
    "timer = Timer() \n",
    "timer.log(\"M1 s \")\n",
    "x1 = m2.flatten(sample)\n",
    "timer.log(\"M1 FL\")\n",
    "x2 = m2.logic_layers[0](x1)\n",
    "timer.log(\"M1 L1\")\n",
    "x3 = m2.logic_layers[1](x2)\n",
    "timer.log(\"M1 L2\")\n",
    "timer.print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "684b1184-47a1-409d-9368-d21bd6cb9ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e446754f-1533-427a-b786-a4f3359169e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model.diff_logic_model.logic_layers[0].indices))\n",
    "print(type(custom_model.custom_diff_logic_model.logic_layers[0].indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "86316f52-8b72-43c3-b93c-89a141f41cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:05<00:00,  6.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9237132352941176"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we run inference on the overall model:\n",
    "\n",
    "model.get_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "96c83028-7cd7-40e8-8e56-a941148001ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 34/34 [00:01<00:00, 19.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12166819852941177"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we try to run inference on the reduced model:\n",
    "custom_model.get_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1e94209c-af67-48af-a57c-1d0c9f03d17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digit0loader = digit_loaders[0]\n",
    "digit1loader = digit_loaders[1]\n",
    "digit4loader = digit_loaders[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "23464d5a-0510-45e7-9501-e45dd6a0f488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <torch.utils.data.dataloader.DataLoader at 0x14fbdab1d1f0>,\n",
       " 1: <torch.utils.data.dataloader.DataLoader at 0x14faa57309d0>,\n",
       " 2: <torch.utils.data.dataloader.DataLoader at 0x14fa7c2f6220>,\n",
       " 3: <torch.utils.data.dataloader.DataLoader at 0x14fa7c2f6340>,\n",
       " 4: <torch.utils.data.dataloader.DataLoader at 0x14fa7c2f67c0>,\n",
       " 5: <torch.utils.data.dataloader.DataLoader at 0x14faa8f69c40>,\n",
       " 6: <torch.utils.data.dataloader.DataLoader at 0x14faa8f69e20>,\n",
       " 7: <torch.utils.data.dataloader.DataLoader at 0x14faa8f69c70>,\n",
       " 8: <torch.utils.data.dataloader.DataLoader at 0x14faa8f69b50>,\n",
       " 9: <torch.utils.data.dataloader.DataLoader at 0x14faa8da4c40>}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "67fbf4ee-f46b-4c90-a39e-78a2bed5395a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 739.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649511160302527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 887.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647666482198857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 863.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075816270060875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 862.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9173584209555432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 869.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9337760560782143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 850.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8906105884523151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 786.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505626268216196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 784.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9260284080427965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 870.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669987087253275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 866.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8902416528315809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in digit_loaders: \n",
    "    print(model.get_accuracy(digit_loaders[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0ac6aa19-b735-499a-95b9-4f0ef6b03028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 736.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02933038184836746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 865.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 871.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033757609297177645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 876.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005718502121379819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 883.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06880649326692492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 880.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16122486626083748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 881.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014757424829367276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 874.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34716841911086516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 878.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49031543995572774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 22/22 [00:00<00:00, 879.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05884523150710201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in digit_loaders: \n",
    "    print(custom_model.get_accuracy(digit_loaders[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9602bab9-509e-4267-858f-fedf2290fbdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### UNUSED CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2805c93b-56ef-4db2-9429-9a3a601baa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# returns the functions used to perform the calculations for each logic gate\n",
    "# currently unused\n",
    "def get_logic_gates_functions_for_layer(connections):\n",
    "    logic_gates_per_layer = []\n",
    "    \n",
    "    # Map integer indices to the corresponding binary operation\n",
    "    for layer_connections in connections:\n",
    "        layer_gates = []\n",
    "        for conn in layer_connections:\n",
    "            layer_gates.append(lambda a, b, i=conn['gate']: bin_op(a, b, i))\n",
    "        logic_gates_per_layer.append(layer_gates)\n",
    "    \n",
    "    return logic_gates_per_layer\n",
    "\n",
    "# gets logic gates for the adjusted connections\n",
    "logic_gates_functions_per_layer_digit_1 = get_logic_gates_functions_for_layer(full_connections_for_digit_1)\n",
    "#logic_gates_functions_per_layer_digit_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d41eb3bc-f739-448a-b469-e622c2b47ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLogicNetwork(\n",
       "  (layers): ModuleList(\n",
       "    (0): CustomLogicLayer(400, 2354, train)\n",
       "    (1): CustomLogicLayer(2157, 1552, train)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the networks for all digits\n",
    "custom_networks = {}\n",
    "for digit in range(10):\n",
    "    adjusted_connections = process_network_with_propagation(connections, unused_gates_per_digit, digit)\n",
    "    logic_gates_per_layer = extract_logic_gates_per_layer(adjusted_connections)\n",
    "    custom_networks[digit] = build_custom_network(adjusted_connections, logic_gates_per_layer)\n",
    "\n",
    "# Test the network for a sample input\n",
    "\n",
    "custom_networks[0](sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e306b9b-b46a-4687-bd4a-286a585afb19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OVERLOAD SUM FUNCTION, \n",
    "# FOR EACH SAMPLE FOR EACH MINI NET\n",
    "# -> SUM THE SECOND LAYER OUTPUTS (1 or 0) SUM ALL ONES\n",
    "# USE WHOLE DATASET (TRANSFORMED BASED ON PREV. CALCULATIONS 20x20, PARTITIONED, BINARIZED) \n",
    "# SAVE CSVs FOR EACH MININET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e3694756-578b-4808-a2b2-ecb7fec52efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connections: all connections for the overall difflogic model\n",
    "# unused_gates_per_digit: gates that were used enough (based on thresholding term) to be considered used\n",
    "# digit: from 0 - 9\n",
    "\n",
    "custom_networks = {}\n",
    "for digit in range(10):\n",
    "    adjusted_connections = process_network_with_propagation(connections, unused_gates_per_digit, digit)\n",
    "    logic_gates = get_logic_gates_for_layer(adjusted_connections)\n",
    "    \n",
    "    custom_networks[digit] = build_custom_network(adjusted_connections, logic_gates)\n",
    "    # fix to that it also physically removes the input nodes only to use the necessary pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e4b51ed5-7514-4064-b2a1-800775e37adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2354, train)\n",
       "     (1): CustomLogicLayer(2499, 1552, train)\n",
       "   )\n",
       " ),\n",
       " 1: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2254, train)\n",
       "     (1): CustomLogicLayer(2499, 1418, train)\n",
       "   )\n",
       " ),\n",
       " 2: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2371, train)\n",
       "     (1): CustomLogicLayer(2500, 1585, train)\n",
       "   )\n",
       " ),\n",
       " 3: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2329, train)\n",
       "     (1): CustomLogicLayer(2500, 1535, train)\n",
       "   )\n",
       " ),\n",
       " 4: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2323, train)\n",
       "     (1): CustomLogicLayer(2499, 1515, train)\n",
       "   )\n",
       " ),\n",
       " 5: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2366, train)\n",
       "     (1): CustomLogicLayer(2499, 1616, train)\n",
       "   )\n",
       " ),\n",
       " 6: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2327, train)\n",
       "     (1): CustomLogicLayer(2499, 1533, train)\n",
       "   )\n",
       " ),\n",
       " 7: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2286, train)\n",
       "     (1): CustomLogicLayer(2499, 1453, train)\n",
       "   )\n",
       " ),\n",
       " 8: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2367, train)\n",
       "     (1): CustomLogicLayer(2500, 1632, train)\n",
       "   )\n",
       " ),\n",
       " 9: CustomLogicNetwork(\n",
       "   (layers): ModuleList(\n",
       "     (0): CustomLogicLayer(400, 2301, train)\n",
       "     (1): CustomLogicLayer(2499, 1525, train)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "309b68b0-d42e-4982-a892-22d944ed94c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lists to store activation counts and gates per layer\n",
    "activation_counts_per_layer = [] \n",
    "gates_per_layer = []  \n",
    "\n",
    "# Hook function to track activations and record gates for each layer\n",
    "def hook_fn_and_record_connections(module, input, output, layer_idx, debug=False):\n",
    "    \"\"\"\n",
    "    Tracks activations and records connections for each neuron in the layer.\n",
    "\n",
    "    Args:\n",
    "    module (nn.Module): The layer being tracked.\n",
    "    input (Tensor): The input to the layer (not used).\n",
    "    output (Tensor): The output from the layer (activations).\n",
    "    layer_idx (int): The index of the layer in the network.\n",
    "    debug (boolean): Whether to print debug information.\n",
    "    \"\"\"\n",
    "    # Initialize activation counts and gates for this layer if not already initialized\n",
    "    if len(activation_counts_per_layer) <= layer_idx:\n",
    "        activation_counts_per_layer.append(np.zeros(output.size(1)))\n",
    "        gates_per_layer.append([])\n",
    "\n",
    "    # Store activations (output > 0 means it fired)\n",
    "    activations = (output > 0).cpu().numpy()\n",
    "\n",
    "    # Update activation counts\n",
    "    activation_counts_per_layer[layer_idx] += activations.sum(axis=0)\n",
    "\n",
    "    # For each neuron in the layer, store its connections if it fires\n",
    "    for neuron_idx, fired in enumerate(activations[0]):  # Assuming batch size of 1 for simplicity\n",
    "        if fired:  # Only consider neurons that fire\n",
    "            # Get the learned gate by taking the argmax of the weights for the neuron\n",
    "            gate_op_idx = module.weights[neuron_idx].argmax().item()\n",
    "            learned_gate = ALL_OPERATIONS[gate_op_idx]\n",
    "\n",
    "            # Get the input connections (indices) for the gate\n",
    "            input_neuron_a = module.indices[0][neuron_idx].item()\n",
    "            input_neuron_b = module.indices[1][neuron_idx].item()\n",
    "\n",
    "            # Record the gate and connections if the neuron fired\n",
    "            gates_per_layer[layer_idx].append({\n",
    "                'Gate': learned_gate,\n",
    "                'Inputs': (input_neuron_a, input_neuron_b),\n",
    "                'a': input_neuron_a,\n",
    "                'b': input_neuron_b\n",
    "            })\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Layer {layer_idx}, Neuron {neuron_idx} fired\")\n",
    "                print(f\"Inputs: {input_neuron_a}, {input_neuron_b}\")\n",
    "                print(f\"Gate: {learned_gate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7962f6-d7d8-4c32-8ded-e006438a7f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST INFERENCE SPEED\n",
    "\n",
    "import time\n",
    "\n",
    "def measure_inference_time(model, data_loader):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, _ in data_loader:\n",
    "            batch_inputs = batch_inputs.to('cuda')\n",
    "            outputs = model.diff_logic_model(batch_inputs)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return total_time\n",
    "\n",
    "# Measure inference time on digit 4 images\n",
    "digit4_inference_time = measure_inference_time(model, digit4_loader)\n",
    "print(f\"Inference time for digit 4 images: {digit4_inference_time:.4f} seconds\")\n",
    "\n",
    "# Measure inference time on all digits (optional)\n",
    "all_digits_inference_time = measure_inference_time(model, test_loader)\n",
    "print(f\"Inference time for all digits: {all_digits_inference_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIFFLOGIC",
   "language": "python",
   "name": "difflogic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
